{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block Chain - Part 1\n",
    "\n",
    "Using the tutorial : https://bigishdata.com/2017/10/17/write-your-own-blockchain-part-1-creating-storing-syncing-displaying-mining-and-proving-work/\n",
    "\n",
    "\n",
    "## Let's build down up\n",
    "Let's construct a block, and it's structure.\n",
    "All it does is, given a dictionary, it acccepts(trusts) all it's data. It works like a dictionary\n",
    "\n",
    "Q: How would create_self_hash() look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(object):\n",
    "    def __init__(self, dictionary):\n",
    "        '''\n",
    "        We're looking for index, timestamp, data, prev_hash, nonce\n",
    "        '''\n",
    "        for k, v in dictionary.items():\n",
    "            setattr(self, k, v)\n",
    "            if not hasattr(self, 'hash'): #in creating the first block, needs to be removed in future\n",
    "                self.hash = self.create_self_hash()\n",
    "\n",
    "    def __dict__(self):\n",
    "        info = {}\n",
    "        info['index'] = str(self.index)\n",
    "        info['timestamp'] = str(self.timestamp)\n",
    "        info['prev_hash'] = str(self.prev_hash)\n",
    "        info['hash'] = str(self.hash)\n",
    "        info['data'] = str(self.data)\n",
    "        return info\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Block<prev_hash: %s,hash: %s>\" % (self.prev_hash, self.hash)\n",
    "    \n",
    "    def create_self_hash(self):\n",
    "        return \"hash placeholder\"\n",
    "    \n",
    "    def self_save(self):\n",
    "        return save_block(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the basic structure, let's create the first block.\n",
    "Notice that the block's prev_hash refers to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_first_block():\n",
    "    block_data = {}\n",
    "    block_data['index'] = 0\n",
    "    block_data['timestamp'] = datetime.datetime.now()\n",
    "    block_data['data'] = 'First block data'\n",
    "    block_data['prev_hash'] = None\n",
    "    block = Block(block_data)\n",
    "    return block\n",
    "new_block = create_first_block()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the folder. Let's call it chaindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chaindata0.json\n",
      "{'index': '0', 'timestamp': '2018-01-31 00:54:07.253190', 'prev_hash': 'None', 'hash': 'hash placeholder', 'data': 'First block data'}\n"
     ]
    }
   ],
   "source": [
    "import os,json\n",
    "\n",
    "chaindata_dir = 'chaindata'\n",
    "\n",
    "def save_block(block):\n",
    "  chaindata_dir = 'chaindata'\n",
    "  filename = '%s%s.json' % (chaindata_dir, block.index)\n",
    "  with open(filename, 'w') as block_file:\n",
    "    print(filename)\n",
    "    print(new_block.__dict__())\n",
    "    json.dump(block.__dict__(), block_file)\n",
    "\n",
    "# make dir\n",
    "if not os.path.exists(chaindata_dir):\n",
    "    os.mkdir(chaindata_dir)\n",
    "# if empty, create first block\n",
    "if os.listdir(chaindata_dir) == []:\n",
    "        first_block = create_first_block()\n",
    "        first_block.self_save() #not implemented yet\n",
    "save_block(new_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync locally - Step by step\n",
    "\n",
    "* Before you start off, you need to sync to the nodes\n",
    "* You can't locally, so we do some emulation\n",
    "* Just read the blocks fromm local data.\n",
    "* In the future, also ave to talk to peers to gather the blocks that were generated while we weren't running the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chaindata chaindata/1.json\n",
      "chaindata chaindata/0.json\n",
      "[<__main__.Block object at 0x7fa4b92d3128>, <__main__.Block object at 0x7fa4b92d3048>]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def sync():\n",
    "    node_blocks = []\n",
    "    \n",
    "    #We're assuming that the folder and at least the initial block exists\n",
    "    chandata_dir = 'chaindata'\n",
    "    \n",
    "    if os.path.exists(chaindata_dir):\n",
    "        \n",
    "        for filename in os.listdir(chaindata_dir):\n",
    "            if filename.endswith('json'):\n",
    "                filepath = '%s/%s' % (chaindata_dir, filename)\n",
    "                print(chaindata_dir,filepath)\n",
    "                with open(filepath, 'r') as block_file:\n",
    "                    block_info = json.load(block_file)\n",
    "                    block_object = Block(block_info)\n",
    "                    node_blocks.append(block_object)\n",
    "    return node_blocks\n",
    "peer_nodes = sync()\n",
    "print(peer_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the blockchain \n",
    "* Use Flask\n",
    "* Do crazy deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chaindata chaindata/1.json\n",
      "chaindata chaindata/0.json\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "node = Flask(__name__)\n",
    "node_blocks = sync()\n",
    "\n",
    "@node.route('/blockchain.json', methods=['GET'])\n",
    "\n",
    "def blockchain():\n",
    "    \"\"\"\n",
    "    Deplots our blockchain\n",
    "    Lists of json of hashes of block info = \n",
    "    [index, timestamp, data, hash, prev_hash]\n",
    "    \"\"\"\n",
    "    \n",
    "    node_blocks = sync() \n",
    "    \n",
    "    # Convert our blocks into dictionaries\n",
    "    python_blocks = []\n",
    "    \n",
    "    for block in node_blocks:\n",
    "        python_blocks.append(block.__dict__())\n",
    "    json_blocks = json.dumps(python_bblocks)\n",
    "    \n",
    "    return json_blocks\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    node.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining\n",
    "\n",
    "* Gonna create header.\n",
    "* Gonna header = index+prev_hash+data+timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple header. Bitcoin header is super complex as compared to this\n",
    "def generate_header(index, prev_hash, data, timestamp, nonce):\n",
    "    return str(index)+prev_hash+data+str(timestamp) + str(nonce)\n",
    "\n",
    "def calculate_hash(index, prev_hash,data, timestamp, nonce):\n",
    "    header_string = generate_header(index, prev_hash, data, timestamp, nonce)\n",
    "    sha = hashlib.sha256()\n",
    "    sha.update(header_string.encode('utf-8'))\n",
    "    return sha.hexdigest()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO the actual mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chaindata chaindata/1.json\n",
      "chaindata chaindata/0.json\n",
      "2018-01-31 00:54:43.892556\n",
      "{'index': '1', 'timestamp': '2018-01-31 00:54:44.064575', 'prev_hash': 'hash placeholder', 'hash': '00002a3a8f710246cd763b4106ac4c7c18f957b9e3bf369a0473f446d23b15bd', 'data': 'I block #0'}\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "node_blocks = sync()\n",
    "NUM_ZEROS = 4\n",
    "def mine(last_block):\n",
    "  index = int(last_block.index) + 1\n",
    "  timestamp = datetime.datetime.now()\n",
    "  print (timestamp)\n",
    "  data = \"I block #%s\" % (int(last_block.index) + 1) #random string for now, not transactions\n",
    "  prev_hash = last_block.hash\n",
    "    \n",
    "  nonce = 0\n",
    "  block_hash = calculate_hash(index, prev_hash, data, timestamp, nonce)\n",
    "  \n",
    "  while str(block_hash[0:NUM_ZEROS]) != '0' * NUM_ZEROS:\n",
    "    nonce += 1\n",
    "    block_hash = calculate_hash(index, prev_hash, data, timestamp, nonce)\n",
    "  block_data = {}\n",
    "  block_data['index'] = int(last_block.index) + 1\n",
    "  block_data['timestamp'] = datetime.datetime.now()\n",
    "  block_data['data'] = \"I block #%s\" % last_block.index\n",
    "  block_data['prev_hash'] = last_block.hash\n",
    "  block_data['hash'] = block_hash\n",
    "  return Block(block_data)\n",
    "\n",
    "def save_block(block):\n",
    "#   chaindata_dir = 'chaindata\n",
    "  filename = '%s/%s.json' % (chaindata_dir, block.index)\n",
    "  with open(filename, 'w') as block_file:\n",
    "    print(new_block.__dict__())\n",
    "    json.dump(block.__dict__(), block_file)\n",
    "\n",
    "last_block = node_blocks[-1]\n",
    "new_block = mine(last_block)\n",
    "save_block(new_block)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
